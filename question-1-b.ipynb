{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T12:05:32.186622Z",
     "iopub.status.busy": "2025-05-15T12:05:32.186147Z",
     "iopub.status.idle": "2025-05-15T12:05:32.192217Z",
     "shell.execute_reply": "2025-05-15T12:05:32.190805Z",
     "shell.execute_reply.started": "2025-05-15T12:05:32.186545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, BartTokenizer, BartForConditionalGeneration, T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:00:54.980431Z",
     "iopub.status.busy": "2025-05-15T11:00:54.980051Z",
     "iopub.status.idle": "2025-05-15T11:00:59.324838Z",
     "shell.execute_reply": "2025-05-15T11:00:59.323720Z",
     "shell.execute_reply.started": "2025-05-15T11:00:54.980403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # General sentence splitting\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pegasus Context\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:46:06.983010Z",
     "iopub.status.busy": "2025-05-15T11:46:06.982700Z",
     "iopub.status.idle": "2025-05-15T11:46:06.989010Z",
     "shell.execute_reply": "2025-05-15T11:46:06.987976Z",
     "shell.execute_reply.started": "2025-05-15T11:46:06.982989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_response_pegasus(input_text,num_return_sequences,num_beams):\n",
    "    batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch,max_length=60, do_sample=True, num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.6)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:51:05.590023Z",
     "iopub.status.busy": "2025-05-15T11:51:05.589105Z",
     "iopub.status.idle": "2025-05-15T11:51:14.148872Z",
     "shell.execute_reply": "2025-05-15T11:51:14.147881Z",
     "shell.execute_reply.started": "2025-05-15T11:51:05.589993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438ec13505e34b6784acded16cccb5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ad3e341b24fcfa5890e4ad553d05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fcb6473c5a4de98edc73e983127ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9161f2f4b3e40fd966b1a52858aef26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56483d4ca88942f1b54b7cf97aa643d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bart Context\n",
    "model_name_bart = 'facebook/bart-base'\n",
    "tokenizer_bart = BartTokenizer.from_pretrained(model_name_bart)\n",
    "model_bart = BartForConditionalGeneration.from_pretrained(model_name_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:53:54.249690Z",
     "iopub.status.busy": "2025-05-15T11:53:54.248730Z",
     "iopub.status.idle": "2025-05-15T11:53:54.255034Z",
     "shell.execute_reply": "2025-05-15T11:53:54.253999Z",
     "shell.execute_reply.started": "2025-05-15T11:53:54.249659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_response_bart(input_text,num_return_sequences,num_beams):\n",
    "    batch = tokenizer_bart([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model_bart.generate(**batch,max_length=60, do_sample=True, num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.6)\n",
    "    tgt_text = tokenizer_bart.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T12:05:39.994336Z",
     "iopub.status.busy": "2025-05-15T12:05:39.993987Z",
     "iopub.status.idle": "2025-05-15T12:05:42.917809Z",
     "shell.execute_reply": "2025-05-15T12:05:42.916813Z",
     "shell.execute_reply.started": "2025-05-15T12:05:39.994288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# T5 Context\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"google-t5/t5-large\", model_max_length=1024)\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T12:06:25.609951Z",
     "iopub.status.busy": "2025-05-15T12:06:25.609582Z",
     "iopub.status.idle": "2025-05-15T12:06:25.615775Z",
     "shell.execute_reply": "2025-05-15T12:06:25.614747Z",
     "shell.execute_reply.started": "2025-05-15T12:06:25.609924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_response_t5(input_text,num_return_sequences,num_beams):\n",
    "    batch = tokenizer_t5([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model_t5.generate(**batch,max_length=60, do_sample=True, num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.6)\n",
    "    tgt_text = tokenizer_t5.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:01:04.866948Z",
     "iopub.status.busy": "2025-05-15T11:01:04.866619Z",
     "iopub.status.idle": "2025-05-15T11:01:04.871919Z",
     "shell.execute_reply": "2025-05-15T11:01:04.870795Z",
     "shell.execute_reply.started": "2025-05-15T11:01:04.866924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weird_sentence = \"\"\"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\n",
    "our lives. Hope you too, to enjoy it as my deepest wishes.\n",
    "Thank your message to show our words to the doctor, as his next contract checking, to all of us.\n",
    "I got this message to see the approved message. In fact, I have received the message from the\n",
    "professor, to show me, this, a couple of days ago. I am very appreciated the full support of the\n",
    "professor, for our Springer proceedings publication\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_sentence_2 = \"\"\"During our final discuss, I told him about the new submission — the one we were waiting since\n",
    "last autumn, but the updates was confusing as it not included the full feedback from reviewer or\n",
    "maybe editor?\n",
    "Anyway, I believe the team, although bit delay and less communication at recent days, they really\n",
    "tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance\n",
    "and eﬀorts until the Springer link came finally last week, I think.\n",
    "Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before\n",
    "he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so.\n",
    "Overall, let us make sure all are safe and celebrate the outcome with strong coﬀee and future\n",
    "targets\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:06:25.883677Z",
     "iopub.status.busy": "2025-05-15T11:06:25.882689Z",
     "iopub.status.idle": "2025-05-15T11:06:25.918601Z",
     "shell.execute_reply": "2025-05-15T11:06:25.917747Z",
     "shell.execute_reply.started": "2025-05-15T11:06:25.883646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in\\nour lives.',\n",
       " 'Hope you too, to enjoy it as my deepest wishes.\\n',\n",
       " 'Thank your message to show our words to the doctor, as his next contract checking, to all of us.\\n',\n",
       " 'I got this message to see the approved message.',\n",
       " 'In fact, I have received the message from the\\nprofessor, to show me, this, a couple of days ago.',\n",
       " 'I am very appreciated the full support of the\\nprofessor, for our Springer proceedings publication']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(weird_sentence)\n",
    "sentences = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(weird_sentence_2)\n",
    "sentences_2 = [sent.text for sent in doc2.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:45:51.934214Z",
     "iopub.status.busy": "2025-05-15T11:45:51.933175Z",
     "iopub.status.idle": "2025-05-15T11:45:51.940902Z",
     "shell.execute_reply": "2025-05-15T11:45:51.939770Z",
     "shell.execute_reply.started": "2025-05-15T11:45:51.934173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def improve_sentence(text, modifierFunction):\n",
    "    num_beams = 10\n",
    "    num_return_sequences = 1\n",
    "    iterations = 2\n",
    "\n",
    "    correctedSentences = []\n",
    "\n",
    "    for sentence in text:\n",
    "        modifiedSentence = sentence\n",
    "        for i in range(iterations):\n",
    "            modifiedSentence = modifierFunction(modifiedSentence,num_return_sequences,num_beams)[0]\n",
    "        correctedSentences.append(modifiedSentence)\n",
    "    return correctedSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:46:23.784649Z",
     "iopub.status.busy": "2025-05-15T11:46:23.784292Z",
     "iopub.status.idle": "2025-05-15T11:47:21.332703Z",
     "shell.execute_reply": "2025-05-15T11:47:21.331750Z",
     "shell.execute_reply.started": "2025-05-15T11:46:23.784626Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Today is the dragon boat festival and it is a great day to celebrate.', 'Hope you enjoy it.', 'You sent a message and showed us our words to the doctor.', 'I saw the message that was approved.', 'A couple of days ago, I received a message from the professor.', 'The Springer proceedings publication was supported by the professor.']\n"
     ]
    }
   ],
   "source": [
    "improved = improve_sentence(sentences, get_response_pegasus)\n",
    "pegasus_text_1 = \"\".join(improved)\n",
    "print(pegasus_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:54:32.093236Z",
     "iopub.status.busy": "2025-05-15T11:54:32.092917Z",
     "iopub.status.idle": "2025-05-15T11:54:56.556915Z",
     "shell.execute_reply": "2025-05-15T11:54:56.555751Z",
     "shell.execute_reply.started": "2025-05-15T11:54:32.093213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great inour lives.', 'Hope you too, to enjoy it as my deepest wishes.', 'Thank your message to show our words to the doctor, as his next contract check, to all of us.', 'I got this message to see the approved message.', 'In fact, I have received the message from the ex-professor, to show me, this, a couple of days ago.', 'I am very appreciated the full support of the board of directors, including the co-professor, for our Springer proceedings.']\n"
     ]
    }
   ],
   "source": [
    "bart_improved = improve_sentence(sentences, get_response_bart)\n",
    "bart_text_1 =  \"\".join(bart_improved)\n",
    "print(bart_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T12:06:50.641903Z",
     "iopub.status.busy": "2025-05-15T12:06:50.641545Z",
     "iopub.status.idle": "2025-05-15T12:10:58.316021Z",
     "shell.execute_reply": "2025-05-15T12:10:58.314897Z",
     "shell.execute_reply.started": "2025-05-15T12:06:50.641881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is our dragon boat festival day, in our Chinese culture to celebrate it with all safe and great in our lives..... dragon boat festival. Today is our dragon boat festival day, in our Chinese culture to celebrate it with all safe and great in our lives.... dragon boat festival. dragon boat festival', '. Hope you too, to enjoy it. Hope you too, to enjoy it. Hope you too, to enjoy it. Hope you too, to enjoy it. Hope you too, to enjoy it. Hope you too.. Hope you too.. Hope you too.. Hope you', 'to all of us. Thank you for your message to show our words to show our words to show our words to show our words to show our words to show our words to show our words to show our words to show our words to show our words to show our words to show our words', 'to see the approved message. I got.. I got this message to see the approved message. I got this message to see the approved message. I got this message to see the approved message.. I got this message to see the approved message. I got to see the', 'I have received the message, to show me, this. In fact, I have received the message, to show me, this. In fact, I have received the message, to show me, this. In fact, I have received the message, to show me, this. In', '. . . . . . . . . . . . . . . . . . . . . . . . . . . . .']\n"
     ]
    }
   ],
   "source": [
    "t5_improved = improve_sentence(sentences, get_response_t5)\n",
    "t5_text_1 =  \"\".join(t5_improved)\n",
    "print(t5_text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved = improve_sentence(sentences_2, get_response_pegasus)\n",
    "pegasus_text_2 = \"\".join(improved)\n",
    "print(pegasus_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_improved = improve_sentence(sentences_2, get_response_bart)\n",
    "bart_text_2 =  \"\".join(bart_improved)\n",
    "print(bart_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_improved = improve_sentence(sentences_2, get_response_t5)\n",
    "t5_text_2 =  \"\".join(t5_improved)\n",
    "print(t5_text_2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
